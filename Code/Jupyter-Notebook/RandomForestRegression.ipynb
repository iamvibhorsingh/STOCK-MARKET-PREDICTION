{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = 'C:\\progra~2\\Java\\jdk1.8.0_231'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[2] pyspark-shell\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"HW2_Submission\").getOrCreate()\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "spark.sparkContext.addFile(\"https://pbda1.s3.amazonaws.com/n2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read .format(\"csv\").option(\"header\", \"true\").load(SparkFiles.get(\"n2.csv\"))\n",
    "df = df.filter(col('SYM').isin(['DJI']))\n",
    "df.columns\n",
    "df = df.withColumn(\"open\", df[\"open\"].cast(\"double\"))\n",
    "df = df.withColumn(\"close\", df[\"close\"].cast(\"double\"))\n",
    "df = df.withColumn(\"high\", df[\"high\"].cast(\"double\"))\n",
    "df = df.withColumn(\"low\", df[\"low\"].cast(\"double\"))\n",
    "df = df.withColumn(\"volume\", df[\"volume\"].cast(\"double\"))\n",
    "df = df.withColumn('change',df[\"close\"]-df[\"open\"])\n",
    "df = df.withColumn('label',df[\"close\"])\n",
    "df = df.withColumn(\"sentiment_score\", df[\"sentiment_score\"].cast(\"double\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer,VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "input_cols = ['open', 'high', 'low', 'close', 'volume','sentiment_score']\n",
    "assembler = [VectorAssembler(inputCols=input_cols, outputCol=\"features\")]\n",
    "pipeline = Pipeline(stages=assembler)\n",
    "df = pipeline.fit(df).transform(df)\n",
    "# df.show()\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
    "scalerModel = scaler.fit(df)\n",
    "result = scalerModel.transform(df)\n",
    "# result.show()\n",
    "\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "res = result.select(\"label\",\"features\")\n",
    "res.printSchema()\n",
    "(trainingData, testData) = res.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.regression.RandomForestRegressionModel'>\n",
      "Root Mean Squared Error (RMSE) on test data = 157.1\n",
      "+------------------+----------+--------------------+\n",
      "|        prediction|     label|            features|\n",
      "+------------------+----------+--------------------+\n",
      "| 26951.97995809257|27881.7207|[27900.6992,27949...|\n",
      "| 26951.97995809257|27909.5996|[27987.0508,28010...|\n",
      "|26969.069520444948|28015.0605|[27839.6797,28035...|\n",
      "| 26951.97995809257|27677.7891|[27736.0508,27745...|\n",
      "|26969.069520444948|27649.7793|[27634.6309,27727...|\n",
      "+------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+--------------------+\n",
      "|     label|            features|\n",
      "+----------+--------------------+\n",
      "|27881.7207|[27900.6992,27949...|\n",
      "|27909.5996|[27987.0508,28010...|\n",
      "|28015.0605|[27839.6797,28035...|\n",
      "|27677.7891|[27736.0508,27745...|\n",
      "|27649.7793|[27634.6309,27727...|\n",
      "|27502.8105|[27501.9805,27524...|\n",
      "|27783.0391|[28109.7402,28109...|\n",
      "|28051.4102|[28103.1602,28119...|\n",
      "|   28164.0|[28156.4707,28174...|\n",
      "|28121.6797|[28080.75,28146.0...|\n",
      "|28066.4707|[27917.7695,28068...|\n",
      "|27875.6191|[27831.2305,27898...|\n",
      "|27766.2891|[27820.2793,27828...|\n",
      "|27821.0898|[27879.5508,27897...|\n",
      "|27934.0195|[28079.7598,28090...|\n",
      "|28036.2207|[27993.2207,28040...|\n",
      "|28004.8906|[27843.5391,28004...|\n",
      "|27781.9609|[27757.1992,27800...|\n",
      "|27783.5898|[27622.0391,27806...|\n",
      "|27691.4902|[27701.5898,27770...|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol=\"features\")\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "print(type(model))\n",
    "\n",
    "predictions = model.transform(res)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\")\n",
    "\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "# model.save(\"stock-model-2.model\")\n",
    "\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "predictions = predictions.withColumn('close',predictions[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
